## Single-Producer/Single Consumer (SP/SC) Wait-Free Ring Buffer [spsc_ring_buffer]

Реализуйте закольцованную очередь на основе буфера фиксированной длины ```spsc_ring_buffer<T>```, которая поддерживала бы две операции:

1) ```bool enqueue(T e)``` - записать элемент ```e``` в хвост очереди и вернуть ```true```, если в буфере есть место для элемента, в противном случае (переполнение) вернуть ```false```

2) ```bool dequeue(T& e)``` - если очередь не пуста, то извлечь элемент из головы очереди и вернуть ```true```, в противном случае вернуть ```false```

Закольцованность означает, что за записью последнего элемента буфера следует запись в первый элемент, т.е. очередь ползает в буфере по кругу.



---

Циклическая очередь должна быть рассчитана только на single-producer/single-consumer режим использования, когда есть единственный-producer поток, который только пишет элементы в очередь, и единственный поток-consumer, который только читает данные из очереди.

Реализация должна быть wait-free: каждая из двух операций должна завершаться за КОНЕЧНОЕ ЧИСЛО ШАГОВ вне зависимости от того, что в данный момент делает другая операция в другом потоке.

wait-freedom - это самая сильная гарантия для конкурентных структур данных, она означает запрет на использование мьютексов и спинлоков, даже честных (fair), т.к. если один из потоков захватит мьютекс или спинлок и будет приостановлен планировщиком, то другой поток не сможет продвигаться дальше. Если же мьютекс или спинлок нечестный, то поток вообще может ожидать сколь угодно долго.

Для синхронизации потоков должны использоваться только атомарные переменные и две модели упорядочивания чтений/записей: relaxed ordering и release/acquire semantics

relaxed ordering гарантирует, что если потоком прочитано значение Y, то тот же поток не может прочитать более старое значение X + гарантирует, что поток всегда видит свои собственные записи

release/acquire-семантика позволяет упорядочить записи и чтения одних и тех же данных между двумя потоками

Обязательно обоснуйте свой выбор memory ordering-а для каждой атомарной операции чтения/записи.

Если не знаете, с чего начать - напишите однопоточную реализацию методов enqueue/dequeue и подумайте, какие проблемы могут возникнуть в случае работы двух потоков.

Подсказка: если переменную может изменить, к примеру, только один поток-producer, то не имеет смысла в методе enqueue использовать атомарное чтение и memory ordering каждый раз, достаточно прочитать значение один раз с нужным memory ordering-ом в локальную переменную.

Подсказка: из атомарных операций не понадобится ничего сложнее store и load.

---

Емкость буфера (```capacity```) должна задаваться с помощью конструктора: ```spsc_ring_buffer<T> ring_buffer(1024)```;

Хранить элементы буфера можно с помощью ```std::vector<T>```

При добавлении/извлечении элементов очередь будет ползать по кругу закольцованного буфера, для работы с ней поддерживайте два индекса:

1) ```head``` - индекс головы очереди - указывает на элемент, который будет извлечен при следующем вызове ```dequeue```

2) ```tail``` - индекс свободного слота за последним элементом в очереди, куда будет записан очередной элемент при следующем вызове ```enqueue```

Тонкий вопрос: как отличить пустую очередь от полной?
Если в ```dequeue``` из очереди извлекается последний элемент, то ```head``` сдвигается вперед и становится равным tail. Когда очередь в enqueue заполняется целиком, то tail сдвигается вперед и тоже начинает совпадать с ```head```. Получаем ```head == tail``` в двух противоположных состояниях, хотя операции должны различать эти состояния.

Для решения этой проблемы можно потребовать, чтобы между хвостом и головой очереди в буфере оставался по крайней мере один свободный слот, тогда проверка на пустоту не меняется (head = tail), а проверка на переполнение становится другой: ```next(tail) = head```, где ```net``` - индекс следующего слота с учетом закольцованности.

Для решения этой же проблемы можно было бы воспользоваться атомарным счетчиком числа элементов, но это было бы менее эффективно: он требовал бы тяжелых операций атомарного инкремента/декремента даже в тех случаях, когда голова и хвост далеко друг от друга и поток-консьюмер никак не пересекается в своей работе с потоком-продьюсером. Кроме того, такое решение не выгодно и с точки зрения синхронизации кэшей.

---

Тест:

Буфер размера L = 1024;

Поток-продьюсер последовательно добавляет в очередь N = 10 000 000 чисел от 1 до N, заодно считает их сумму, после чего возвращает значение:

spsc_ring_buffer<int> channel(capacity);

std::future<uint64_t> produced_sum = std::async(producer_work_loop, std::ref(channel));

Поток-продьюсер получает все эти числа и тоже складывает их:

std::future<uint64_t> consumed_sum = std::async(consumer_work_loop, std::ref(channel));

Если поток-продьюсер не может положить элемент в циклическую очередь из-за переполнения или поток-консьюмер не может извлечь очередьной элемент из-за того, что очередь пуста, то они делают std::this_thread::yield() до тех пор, пока операция не завершится успешно.

Ни один из потоков ничего не печатает на экран, только добавляет в очередь/вычитывает числа и считает сумму. Важно, чтобы поток-продьюсер и поток-консьюмер делали один и тот же объем работы, иначе очередь будет либо почти все время полная, либо почти все время пустая, тогда никакой конкурентной работы потоков не будет.

---

Сравните производительность wait-free ring-buffer-а и обычной потоко-безопасной очереди.

----

False sharing:

1)
Если в очереди в какой-то момент окажется мало элементов и все они попадут в одну кэш-линию, то при записи в buf[tail] поток-продьюсер инвалидирует эту кэш-линию в кэше потока-консьюмера, и для чтения из buf[head] кэшу консьюмера нужно будет посылать на шину запрос на чтение (BusRd) и ждать, пока он получит строку себе.

2)
Только поток-продьюсер изменяет индекс tail, и только поток-консьюмер изменяет индекс head. Если эти индексы хранятся в одной кэш-линии, то поток-продьюсер и поток-консьюмер при записи этих индексов будут двигать кэш-линию к себе в кэш, а значит на записи будет синхронизация на уровне протокола когерентности, хотя  реальности она не нужна.


Используйте технику padding для предотвращения false sharing в циклической очереди

1) Вместо  std::vector<T> храните std::vector<node_t>, где node_t будет хранить сам объект типа T + массив байтов char pad[CACHE_LINE_SIZE], который бы гарантровал, что разные элементы T попадают в разные кэш-линии

2) Поместите head и tail в разные кэш-линии

Сравните производительность ring-buffer-а без этих оптимизаций, с оптимизацией 1), с оптимизацией 1) и 2)

-----

Подсказки и требования к реализации:

1. Помимо вектора-буфера и поля, хранящего ```capacity```, для реализации циклической очереди достаточно ровно двух переменных ```head``` и ```tail```. И продьюсер и консьюмер в ```enqueue/dequeue``` читают ```head и tail```, причем продьюсер пишет ```tail```, а консьюмер - ```head```, так что для корректной работы очереди в двух потоках ```head``` и ```tail``` должны быть атомарными (```std::atomic<size_t>```).

2. Потоку-продьюсеру и потоку-консьюмеру в ```enqueue/dequeue``` нужно считывать значения ```head``` и ```tail``` несколько раз.

Например, продьюсеру нужно прочитать ```head``` и ```tail```, чтобы понять, что очередь не переполнилась, потом записать ```buf[tail]```, потом записать новое значение ```tail + 1```. У консьюмера все точно так же, только для ```head```.

Каждое такое обращение - это атомарное чтение, и каждый раз нужно думать, какой ```memory order``` для этого чтения выбрать.

Но если задуматься, то станет ясно, что в ```enqueue/dequeue``` достаточно ровно одного атомарного чтения ```head``` и одного атомарного чтения ```tail```:
```
size_t curr_head = head.load(?);
size_t curr_tail = tail.load(?);
```
Дальше можно проверять переполнение/пустоту очереди, делать операции и т.д., и использовать только простые локальные копии ```curr_tail``` и ```curr_head```, ничего плохого не случится, и вот почему:

Пусть мы в методе ```enqueue```:

Если мы сохранили в ```curr_tail``` значение ```tail```, то оно гарантированно больше не измениться, т.к. только продьюсер его меняет, а продьюсер только один, и он выполняет текущий ```enqueue```.

Если мы сохранили в ```curr_head``` значение ```head```, то оно может изменяться, но только в лучшую сторону: консьюмер может извлекать элементы, но этим он только освобождает в очереди больше места, а продьюсера волнует только ситуация, когда очередь переполняется.

С точки зрения ```dequeue``` ситуация симметричная: ```head``` и ```curr_head``` будут совпадать, а ```tail``` может уходить вперед от ```curr_tail```, но метод ```dequeue``` беспокоит только случай, когда очередь пуста, а увеличение ```tail``` говорит о появлении новых элементов, т.е. ситуация хуже не станет.

3. И в ```enqueue```, и в ```dequeue``` достаточно только одной записи в атомарную переменную: enqueue двигает вперед только ```tail```, ```dequeue``` - только ```head```.
